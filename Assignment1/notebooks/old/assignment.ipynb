{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import json\n",
    "from naivebayes import NaiveBayesTextClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('SNOWFLAKE_USER')\n",
    "password = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "account = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "warehouse = os.getenv('SNOWFLAKE_WAREHOUSE')\n",
    "database = os.getenv('SNOWFLAKE_DATABASE')\n",
    "schema = os.getenv('SNOWFLAKE_SCHEMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    f'snowflake://{username}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM MODEL_PARAMETERS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(query))\n",
    "    rows = result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('yelp_review_full/yelp_review_full/train-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('yelp_review_full/yelp_review_full/test-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['label'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['label'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesTextClassifier()\n",
    "classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.word_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(test['label'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "training_data = vectorizer.fit_transform(train['text'][:1000])\n",
    "test_data = vectorizer.transform(test['text'][:100])\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "nb_classifier.fit(training_data.toarray(), list(train['label'][:1000]))\n",
    "\n",
    "y_pred = nb_classifier.predict(test_data.toarray())\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = {}\n",
    "# for i,j in Counter(train['label']).items():\n",
    "#     priors[i] = j/len(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_per_label_dict = {}\n",
    "# for label, vector in zip(list(train['label']), X.toarray()):\n",
    "#     if label in vocab_per_label_dict:\n",
    "#         vocab_per_label_dict[label] += vector\n",
    "#     else:\n",
    "#         vocab_per_label_dict[label] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_per_label = {}\n",
    "# for i, j in vocab_per_label_dict.items():\n",
    "#     total_per_label[i] = np.sum(j)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_probabilities = {}\n",
    "# for i,j in vocab_per_label_dict.items():\n",
    "#     word_prob_list = []\n",
    "#     for k in j:\n",
    "#         if k != 0:\n",
    "#             prob = k/total_per_label[i]\n",
    "#             word_prob_list.append(prob)\n",
    "#         else:\n",
    "#             word_prob_list.append(0)\n",
    "#     word_probabilities[i] = np.array(word_prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = dict()\n",
    "# for label in word_probabilities.keys():\n",
    "#     test = []\n",
    "#     for i,j in zip(word_probabilities[label],y.toarray()[0]):\n",
    "#         if i == 0:\n",
    "#             test.append(1)\n",
    "#         else:\n",
    "#             test.append(i**j)\n",
    "#     results[label] = priors[label]*math.prod(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_key = max(results, key=lambda k: results[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NaiveBayesTextClassifier:\n",
    "#     def __init__(self):\n",
    "#         self.vectorizer = CountVectorizer()\n",
    "#         self.priors = {}\n",
    "#         self.vocab_per_label_dict = {}\n",
    "#         self.total_per_label = {}\n",
    "#         self.word_probabilities = {}\n",
    "    \n",
    "#     def fit(self, train_texts, train_labels):\n",
    "#         X = self.vectorizer.fit_transform(train_texts)\n",
    "#         self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "#         label_counts = Counter(train_labels)\n",
    "#         self.priors = {label: count / len(train_labels) for label, count in label_counts.items()}\n",
    "        \n",
    "#         for label, vector in zip(train_labels, X.toarray()):\n",
    "#             if label in self.vocab_per_label_dict:\n",
    "#                 self.vocab_per_label_dict[label] += vector\n",
    "#             else:\n",
    "#                 self.vocab_per_label_dict[label] = vector\n",
    "        \n",
    "#         self.total_per_label = {label: np.sum(vector) for label, vector in self.vocab_per_label_dict.items()}\n",
    "        \n",
    "#         self.word_probabilities = {}\n",
    "#         for label, vector in self.vocab_per_label_dict.items():\n",
    "#             word_prob_list = [count / self.total_per_label[label] if count != 0 else 0 for count in vector]\n",
    "#             self.word_probabilities[label] = np.array(word_prob_list)\n",
    "    \n",
    "#     def predict(self, test_texts):\n",
    "#             # Vectorize the test data\n",
    "#             X_test = self.vectorizer.transform(test_texts)\n",
    "#             predictions = []\n",
    "            \n",
    "#             # Iterate over each test document\n",
    "#             for test_vector in X_test.toarray():\n",
    "#                 results = {}\n",
    "                \n",
    "#                 # For each label, compute the likelihood for the current test document\n",
    "#                 for label in self.word_probabilities.keys():\n",
    "#                     class_probabilities = []\n",
    "#                     for i, word_count in enumerate(test_vector):\n",
    "#                         word_prob = self.word_probabilities[label][i]\n",
    "#                         if word_prob == 0:\n",
    "#                             class_probabilities.append(1)\n",
    "#                         else:\n",
    "#                             class_probabilities.append(word_prob ** word_count)\n",
    "                    \n",
    "#                     # Multiply all word probabilities and store the result for the label\n",
    "#                     results[label] = math.prod(class_probabilities)\n",
    "                \n",
    "#                 # Select the label with the highest likelihood\n",
    "#                 max_key = max(results, key=lambda k: results[k])\n",
    "#                 predictions.append(max_key)\n",
    "            \n",
    "#             return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = NaiveBayesTextClassifier()\n",
    "# classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import numpy as np\n",
    "# from collections import Counter\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from functools import reduce\n",
    "# import operator\n",
    "\n",
    "# class NaiveBayesTextClassifier:\n",
    "#     def __init__(self):\n",
    "#         self.vectorizer = CountVectorizer()\n",
    "#         self.priors = {}\n",
    "#         self.vocab_per_label_dict = {}\n",
    "#         self.total_per_label = {}\n",
    "#         self.word_probabilities = {}\n",
    "    \n",
    "#     def fit(self, train_texts, train_labels):\n",
    "#         X = self.vectorizer.fit_transform(train_texts)\n",
    "#         self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "#         label_counts = Counter(train_labels)\n",
    "#         self.priors = {label: count / len(train_labels) for label, count in label_counts.items()}\n",
    "        \n",
    "#         for label, vector in zip(train_labels, X.toarray()):\n",
    "#             if label in self.vocab_per_label_dict:\n",
    "#                 self.vocab_per_label_dict[label] += vector\n",
    "#             else:\n",
    "#                 self.vocab_per_label_dict[label] = vector\n",
    "        \n",
    "#         self.total_per_label = {label: np.sum(vector) for label, vector in self.vocab_per_label_dict.items()}\n",
    "        \n",
    "#         self.word_probabilities = {}\n",
    "#         for label, vector in self.vocab_per_label_dict.items():\n",
    "#             word_prob_list = [(count + 1) / (self.total_per_label[label] + len(self.feature_names)) \n",
    "#                               for count in vector]  # Laplace Smoothing\n",
    "\n",
    "#             # word_prob_list = [count / self.total_per_label[label] if count != 0 else 0 for count in vector]\n",
    "\n",
    "#             self.word_probabilities[label] = np.array(word_prob_list)\n",
    "    \n",
    "#     def predict(self, test_texts):\n",
    "#         X_test = self.vectorizer.transform(test_texts)\n",
    "#         predictions = []\n",
    "        \n",
    "#         for test_vector in X_test.toarray():\n",
    "#             results = {}\n",
    "            \n",
    "#             for label in self.word_probabilities.keys():\n",
    "#                 class_probabilities = []\n",
    "#                 for i, word_count in enumerate(test_vector):\n",
    "#                     word_prob = self.word_probabilities[label][i]\n",
    "#                     if word_prob > 0:\n",
    "#                         class_probabilities.append(word_count * math.log(word_prob))                \n",
    "#                 results[label] = math.log(self.priors[label]) + sum(class_probabilities)\n",
    "            \n",
    "#             max_key = max(results, key=lambda k: results[k])\n",
    "#             predictions.append(max_key)\n",
    "        \n",
    "#         return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = NaiveBayesTextClassifier()\n",
    "# classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
