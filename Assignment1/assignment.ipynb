{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import json\n",
    "from naivebayes import NaiveBayesTextClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('SNOWFLAKE_USER')\n",
    "password = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "account = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "warehouse = os.getenv('SNOWFLAKE_WAREHOUSE')\n",
    "database = os.getenv('SNOWFLAKE_DATABASE')\n",
    "schema = os.getenv('SNOWFLAKE_SCHEMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flo/Desktop/ITU/MSc/3rd_semester/ADS/.venv/lib/python3.12/site-packages/snowflake/sqlalchemy/base.py:1068: SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.\n",
      "  functions.register_function(\"flatten\", flatten)\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "    f'snowflake://{username}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(query))\n",
    "    rows = result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame([json.loads(rows[i][0]) for i in range(len(rows))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['label'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM Test LIMIT 500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(query))\n",
    "    rows = result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame([json.loads(rows[i][0]) for i in range(len(rows))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['label'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesTextClassifier()\n",
    "classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier.word_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ndarrays(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_ndarrays(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_ndarrays(item) for item in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_data = convert_ndarrays(classifier.word_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordprobabilities.json', 'w') as json_file:\n",
    "    json.dump(converted_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58        87\n",
      "           1       0.70      0.77      0.73       119\n",
      "\n",
      "    accuracy                           0.67       206\n",
      "   macro avg       0.67      0.66      0.66       206\n",
      "weighted avg       0.67      0.67      0.67       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = {}\n",
    "# for i,j in Counter(train['label']).items():\n",
    "#     priors[i] = j/len(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_per_label_dict = {}\n",
    "# for label, vector in zip(list(train['label']), X.toarray()):\n",
    "#     if label in vocab_per_label_dict:\n",
    "#         vocab_per_label_dict[label] += vector\n",
    "#     else:\n",
    "#         vocab_per_label_dict[label] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_per_label = {}\n",
    "# for i, j in vocab_per_label_dict.items():\n",
    "#     total_per_label[i] = np.sum(j)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_probabilities = {}\n",
    "# for i,j in vocab_per_label_dict.items():\n",
    "#     word_prob_list = []\n",
    "#     for k in j:\n",
    "#         if k != 0:\n",
    "#             prob = k/total_per_label[i]\n",
    "#             word_prob_list.append(prob)\n",
    "#         else:\n",
    "#             word_prob_list.append(0)\n",
    "#     word_probabilities[i] = np.array(word_prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = dict()\n",
    "# for label in word_probabilities.keys():\n",
    "#     test = []\n",
    "#     for i,j in zip(word_probabilities[label],y.toarray()[0]):\n",
    "#         if i == 0:\n",
    "#             test.append(1)\n",
    "#         else:\n",
    "#             test.append(i**j)\n",
    "#     results[label] = priors[label]*math.prod(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_key = max(results, key=lambda k: results[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NaiveBayesTextClassifier:\n",
    "#     def __init__(self):\n",
    "#         self.vectorizer = CountVectorizer()\n",
    "#         self.priors = {}\n",
    "#         self.vocab_per_label_dict = {}\n",
    "#         self.total_per_label = {}\n",
    "#         self.word_probabilities = {}\n",
    "    \n",
    "#     def fit(self, train_texts, train_labels):\n",
    "#         X = self.vectorizer.fit_transform(train_texts)\n",
    "#         self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "#         label_counts = Counter(train_labels)\n",
    "#         self.priors = {label: count / len(train_labels) for label, count in label_counts.items()}\n",
    "        \n",
    "#         for label, vector in zip(train_labels, X.toarray()):\n",
    "#             if label in self.vocab_per_label_dict:\n",
    "#                 self.vocab_per_label_dict[label] += vector\n",
    "#             else:\n",
    "#                 self.vocab_per_label_dict[label] = vector\n",
    "        \n",
    "#         self.total_per_label = {label: np.sum(vector) for label, vector in self.vocab_per_label_dict.items()}\n",
    "        \n",
    "#         self.word_probabilities = {}\n",
    "#         for label, vector in self.vocab_per_label_dict.items():\n",
    "#             word_prob_list = [count / self.total_per_label[label] if count != 0 else 0 for count in vector]\n",
    "#             self.word_probabilities[label] = np.array(word_prob_list)\n",
    "    \n",
    "#     def predict(self, test_texts):\n",
    "#             # Vectorize the test data\n",
    "#             X_test = self.vectorizer.transform(test_texts)\n",
    "#             predictions = []\n",
    "            \n",
    "#             # Iterate over each test document\n",
    "#             for test_vector in X_test.toarray():\n",
    "#                 results = {}\n",
    "                \n",
    "#                 # For each label, compute the likelihood for the current test document\n",
    "#                 for label in self.word_probabilities.keys():\n",
    "#                     class_probabilities = []\n",
    "#                     for i, word_count in enumerate(test_vector):\n",
    "#                         word_prob = self.word_probabilities[label][i]\n",
    "#                         if word_prob == 0:\n",
    "#                             class_probabilities.append(1)\n",
    "#                         else:\n",
    "#                             class_probabilities.append(word_prob ** word_count)\n",
    "                    \n",
    "#                     # Multiply all word probabilities and store the result for the label\n",
    "#                     results[label] = math.prod(class_probabilities)\n",
    "                \n",
    "#                 # Select the label with the highest likelihood\n",
    "#                 max_key = max(results, key=lambda k: results[k])\n",
    "#                 predictions.append(max_key)\n",
    "            \n",
    "#             return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = NaiveBayesTextClassifier()\n",
    "# classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import numpy as np\n",
    "# from collections import Counter\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from functools import reduce\n",
    "# import operator\n",
    "\n",
    "# class NaiveBayesTextClassifier:\n",
    "#     def __init__(self):\n",
    "#         self.vectorizer = CountVectorizer()\n",
    "#         self.priors = {}\n",
    "#         self.vocab_per_label_dict = {}\n",
    "#         self.total_per_label = {}\n",
    "#         self.word_probabilities = {}\n",
    "    \n",
    "#     def fit(self, train_texts, train_labels):\n",
    "#         X = self.vectorizer.fit_transform(train_texts)\n",
    "#         self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "#         label_counts = Counter(train_labels)\n",
    "#         self.priors = {label: count / len(train_labels) for label, count in label_counts.items()}\n",
    "        \n",
    "#         for label, vector in zip(train_labels, X.toarray()):\n",
    "#             if label in self.vocab_per_label_dict:\n",
    "#                 self.vocab_per_label_dict[label] += vector\n",
    "#             else:\n",
    "#                 self.vocab_per_label_dict[label] = vector\n",
    "        \n",
    "#         self.total_per_label = {label: np.sum(vector) for label, vector in self.vocab_per_label_dict.items()}\n",
    "        \n",
    "#         self.word_probabilities = {}\n",
    "#         for label, vector in self.vocab_per_label_dict.items():\n",
    "#             word_prob_list = [(count + 1) / (self.total_per_label[label] + len(self.feature_names)) \n",
    "#                               for count in vector]  # Laplace Smoothing\n",
    "\n",
    "#             # word_prob_list = [count / self.total_per_label[label] if count != 0 else 0 for count in vector]\n",
    "\n",
    "#             self.word_probabilities[label] = np.array(word_prob_list)\n",
    "    \n",
    "#     def predict(self, test_texts):\n",
    "#         X_test = self.vectorizer.transform(test_texts)\n",
    "#         predictions = []\n",
    "        \n",
    "#         for test_vector in X_test.toarray():\n",
    "#             results = {}\n",
    "            \n",
    "#             for label in self.word_probabilities.keys():\n",
    "#                 class_probabilities = []\n",
    "#                 for i, word_count in enumerate(test_vector):\n",
    "#                     word_prob = self.word_probabilities[label][i]\n",
    "#                     if word_prob > 0:\n",
    "#                         class_probabilities.append(word_count * math.log(word_prob))                \n",
    "#                 results[label] = math.log(self.priors[label]) + sum(class_probabilities)\n",
    "            \n",
    "#             max_key = max(results, key=lambda k: results[k])\n",
    "#             predictions.append(max_key)\n",
    "        \n",
    "#         return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = NaiveBayesTextClassifier()\n",
    "# classifier.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = classifier.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
