{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_create(sf):\n",
    "    con = duckdb.connect(f'database_{sf}.duckdb')\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE customer\n",
    "    (\n",
    "        C_CUSTKEY       INTEGER,\n",
    "        C_NAME          VARCHAR,\n",
    "        C_ADDRESS       VARCHAR,\n",
    "        C_CITY          VARCHAR,\n",
    "        C_NATION        VARCHAR,\n",
    "        C_REGION        VARCHAR,\n",
    "        C_PHONE         VARCHAR,\n",
    "        C_MKTSEGMENT    VARCHAR\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE lineorder\n",
    "    (\n",
    "        LO_ORDERKEY             INTEGER,\n",
    "        LO_LINENUMBER           INTEGER,\n",
    "        LO_CUSTKEY              INTEGER,\n",
    "        LO_PARTKEY              INTEGER,\n",
    "        LO_SUPPKEY              INTEGER,\n",
    "        LO_ORDERDATE            VARCHAR,\n",
    "        LO_ORDERPRIORITY        VARCHAR,\n",
    "        LO_SHIPPRIORITY         INTEGER,\n",
    "        LO_QUANTITY             INTEGER,\n",
    "        LO_EXTENDEDPRICE        INTEGER,\n",
    "        LO_ORDTOTALPRICE        INTEGER,\n",
    "        LO_DISCOUNT             INTEGER,\n",
    "        LO_REVENUE              INTEGER,\n",
    "        LO_SUPPLYCOST           INTEGER,\n",
    "        LO_TAX                  INTEGER,\n",
    "        LO_COMMITDATE           VARCHAR,\n",
    "        LO_SHIPMODE             VARCHAR\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE part\n",
    "    (\n",
    "            P_PARTKEY       INTEGER,\n",
    "            P_NAME          VARCHAR,\n",
    "            P_MFGR          VARCHAR,\n",
    "            P_CATEGORY      VARCHAR,\n",
    "            P_BRAND         VARCHAR,\n",
    "            P_COLOR         VARCHAR,\n",
    "            P_TYPE          VARCHAR,\n",
    "            P_SIZE          INTEGER,\n",
    "            P_CONTAINER     VARCHAR\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE supplier\n",
    "    (\n",
    "            S_SUPPKEY       INTEGER,\n",
    "            S_NAME          VARCHAR,\n",
    "            S_ADDRESS       VARCHAR,\n",
    "            S_CITY          VARCHAR,\n",
    "            S_NATION        VARCHAR,\n",
    "            S_REGION        VARCHAR,\n",
    "            S_PHONE         VARCHAR\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE date\n",
    "    (\n",
    "            D_DATEKEY            VARCHAR,\n",
    "            D_DATE               VARCHAR,\n",
    "            D_DAYOFWEEK          VARCHAR,\n",
    "            D_MONTH              VARCHAR,\n",
    "            D_YEAR               INTEGER,\n",
    "            D_YEARMONTHNUM       INTEGER,\n",
    "            D_YEARMONTH          VARCHAR,\n",
    "            D_DAYNUMINWEEK       INTEGER,\n",
    "            D_DAYNUMINMONTH      INTEGER,\n",
    "            D_DAYNUMINYEAR       INTEGER,\n",
    "            D_MONTHNUMINYEAR     INTEGER,\n",
    "            D_WEEKNUMINYEAR      INTEGER,\n",
    "            D_SELLINGSEASON      VARCHAR,\n",
    "            D_LASTDAYINWEEKFL    INTEGER,\n",
    "            D_LASTDAYINMONTHFL   INTEGER,\n",
    "            D_HOLIDAYFL          INTEGER,\n",
    "            D_WEEKDAYFL          INTEGER\n",
    "    )\n",
    "    \"\"\")\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_create(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_create(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_create(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_path, sf):\n",
    "    con = duckdb.connect(f'database_{sf}.duckdb')\n",
    "    \n",
    "    try:\n",
    "        con.execute(f\"COPY customer FROM '{data_path}/customer.tbl' (HEADER);\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing customer data: {e}\")\n",
    "    \n",
    "    try:\n",
    "        con.execute(f\"COPY lineorder FROM '{data_path}/lineorder.tbl' (HEADER);\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing lineorder data: {e}\")\n",
    "    \n",
    "    try:\n",
    "        con.execute(f\"COPY part FROM '{data_path}/part.tbl' (HEADER);\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing part data: {e}\")\n",
    "    \n",
    "    try:\n",
    "        con.execute(f\"COPY supplier FROM '{data_path}/supplier.tbl' (HEADER);\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing supplier data: {e}\")\n",
    "    \n",
    "    try:\n",
    "        con.execute(f\"COPY date FROM '{data_path}/date.tbl' (HEADER);\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error importing date data: {e}\")\n",
    "    \n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import('data/sf_1',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import('data/sf_10',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import('data/sf_50',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_run(sf, thread_count, folder,run_no):\n",
    "    profiling_folder = f'results/tc_{thread_count}/{folder}'\n",
    "    os.makedirs(profiling_folder, exist_ok=True)\n",
    "\n",
    "    con = duckdb.connect(f'database_{sf}.duckdb')\n",
    "\n",
    "    con.execute(f\"PRAGMA threads={thread_count};\")\n",
    "\n",
    "    queries = [\n",
    "    \"SELECT sum(LO_EXTENDEDPRICE * LO_DISCOUNT) AS REVENUE FROM lineorder, date WHERE LO_ORDERDATE = D_DATEKEY AND D_YEAR = 1993 AND LO_DISCOUNT BETWEEN 1 AND 3 AND LO_QUANTITY < 25;\",\n",
    "    \"SELECT sum(LO_REVENUE), D_YEAR, P_BRAND FROM lineorder, date, part, supplier WHERE LO_ORDERDATE = D_DATEKEY AND LO_PARTKEY = P_PARTKEY AND LO_SUPPKEY = S_SUPPKEY AND P_CATEGORY = 'MFGR#12' AND S_REGION = 'AMERICA' GROUP BY D_YEAR, P_BRAND ORDER BY D_YEAR, P_BRAND;\",\n",
    "    \"SELECT C_NATION, S_NATION, D_YEAR, sum(LO_REVENUE) AS REVENUE FROM customer, lineorder, supplier, date WHERE LO_CUSTKEY = C_CUSTKEY AND LO_SUPPKEY = S_SUPPKEY AND LO_ORDERDATE = D_DATEKEY AND C_REGION = 'ASIA' AND S_REGION = 'ASIA' AND D_YEAR >= 1992 AND D_YEAR <= 1997 GROUP BY C_NATION, S_NATION, D_YEAR ORDER BY D_YEAR ASC, REVENUE DESC;\",\n",
    "    \"SELECT D_YEAR, C_NATION, sum(LO_REVENUE - LO_SUPPLYCOST) AS PROFIT FROM date, customer, supplier, part, lineorder WHERE LO_CUSTKEY = C_CUSTKEY AND LO_SUPPKEY = S_SUPPKEY AND LO_PARTKEY = P_PARTKEY AND LO_ORDERDATE = D_DATEKEY AND C_REGION = 'AMERICA' AND S_REGION = 'AMERICA' AND (P_MFGR = 'MFGR#1' OR P_MFGR = 'MFGR#2') GROUP BY D_YEAR, C_NATION ORDER BY D_YEAR, C_NATION;\"\n",
    "    ]\n",
    "\n",
    "    for idx, query in enumerate(queries, start=1):\n",
    "        profiling_output = f\"{profiling_folder}/query_{idx}_profile_run_{run_no}.json\"\n",
    "        \n",
    "        con.execute(\"PRAGMA enable_profiling='json';\")\n",
    "        con.execute(f\"PRAGMA profiling_output='{profiling_output}';\")\n",
    "\n",
    "        con.execute(query)\n",
    "        \n",
    "        con.execute(\"PRAGMA disable_profiling;\")\n",
    "    \n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    query_run(1,1,'sf_1',i)\n",
    "    query_run(1,4,'sf_1',i)\n",
    "    query_run(1,8,'sf_1',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    query_run(10,1,'sf_10',i)\n",
    "    query_run(10,4,'sf_10',i)\n",
    "    query_run(10,8,'sf_10',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    query_run(50,1,'sf_50',i)\n",
    "    query_run(50,4,'sf_50',i)\n",
    "    query_run(50,8,'sf_50',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tc,sf):\n",
    "    base_dir = f\"results/{tc}/{sf}\"  \n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for file_name in sorted(os.listdir(base_dir)):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            parts = file_name.split(\"_\")\n",
    "            query_number = int(parts[1])  \n",
    "            run_number = int(parts[-1].split(\".\")[0])  \n",
    "\n",
    "            file_path = os.path.join(base_dir, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            data_list.append({\n",
    "                \"query\": query_number,\n",
    "                \"run_number\": run_number,\n",
    "                \"latency\": data[\"latency\"],\n",
    "                \"cpu_time\": data[\"cpu_time\"],\n",
    "                \"cumulative_rows_scanned\": data['cumulative_rows_scanned']\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_1 = get_data('tc_8','sf_1')\n",
    "df_4_1 = get_data('tc_4','sf_1')\n",
    "df_1_1 = get_data('tc_1','sf_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_1['Scaling Factor'] = 1\n",
    "df_4_1['Scaling Factor'] = 1\n",
    "df_1_1['Scaling Factor'] = 1\n",
    "\n",
    "df_8_1['Threads'] = 8\n",
    "df_4_1['Threads'] = 4\n",
    "df_1_1['Threads'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_50 = get_data('tc_8','sf_50')\n",
    "df_4_50 = get_data('tc_4','sf_50')\n",
    "df_1_50 = get_data('tc_1','sf_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_50['Scaling Factor'] = 50\n",
    "df_4_50['Scaling Factor'] = 50\n",
    "df_1_50['Scaling Factor'] = 50\n",
    "\n",
    "df_8_50['Threads'] = 8\n",
    "df_4_50['Threads'] = 4\n",
    "df_1_50['Threads'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_10 = get_data('tc_8','sf_10')\n",
    "df_4_10 = get_data('tc_4','sf_10')\n",
    "df_1_10 = get_data('tc_1','sf_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8_10['Scaling Factor'] = 10\n",
    "df_4_10['Scaling Factor'] = 10\n",
    "df_1_10['Scaling Factor'] = 10\n",
    "\n",
    "df_8_10['Threads'] = 8\n",
    "df_4_10['Threads'] = 4\n",
    "df_1_10['Threads'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df_1_1, df_4_1, df_8_1,\n",
    "    df_1_10, df_4_10, df_8_10,\n",
    "    df_1_50, df_4_50, df_8_50\n",
    "])\n",
    "\n",
    "mean_cpu_times = (\n",
    "    combined_df\n",
    "    .groupby(['Scaling Factor', 'Threads'])['cpu_time']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bar_width = 0.2\n",
    "positions = [-bar_width, 0, bar_width]\n",
    "\n",
    "scaling_factors = mean_cpu_times['Scaling Factor'].unique()\n",
    "for i, sf in enumerate(scaling_factors):\n",
    "    subset = mean_cpu_times[mean_cpu_times['Scaling Factor'] == sf]\n",
    "    plt.bar(\n",
    "        subset['Threads'] + positions[i],  # Adjust bar positions\n",
    "        subset['cpu_time'],               # Heights of the bars\n",
    "        width=bar_width,                  # Bar width\n",
    "        label=f'SF: {sf}',                # Label with scaling factor\n",
    "        edgecolor='black'                 # Bar edge color\n",
    "    )\n",
    "\n",
    "plt.xlabel('Thread Count', fontsize=12)\n",
    "plt.ylabel('Mean CPU Time (s)', fontsize=12)\n",
    "plt.title('Mean CPU Time by Thread Count and Scaling Factor', fontsize=14)\n",
    "\n",
    "plt.xticks([1, 4, 8], ['1', '4', '8'], fontsize=10)\n",
    "\n",
    "plt.legend(title='Scaling Factor', fontsize=10, title_fontsize=12, loc='center left',bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_1_1, df_4_1, df_8_1,df_1_10, df_4_10, df_8_10, df_1_50, df_4_50, df_8_50])\n",
    "\n",
    "mean_latency = combined_df.groupby(['Scaling Factor', 'Threads'])['latency'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bar_width = 0.2\n",
    "positions = [-bar_width, 0, bar_width]\n",
    "\n",
    "for i, sf in enumerate(mean_latency['Scaling Factor'].unique()):\n",
    "    subset = mean_latency[mean_latency['Scaling Factor'] == sf]\n",
    "    plt.bar(\n",
    "        subset['Threads'] + positions[i],\n",
    "        subset['latency'],\n",
    "        width=bar_width,\n",
    "        label=sf,\n",
    "        edgecolor = 'black'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Thread Count')\n",
    "plt.ylabel('Mean Latency (s)')\n",
    "plt.title('Mean Latency by Thread Count and Scaling Factor')\n",
    "plt.xticks([1, 4, 8], ['1', '4', '8'])\n",
    "plt.legend(title='Scaling Factor', fontsize=10, title_fontsize=12, loc='center left',bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"TC 1 | SF 1\": df_1_1,\n",
    "    \"TC 4 | SF 1\": df_4_1,\n",
    "    \"TC 8 | SF 1\": df_8_1,\n",
    "    \"TC 1 | SF 10\": df_1_10,\n",
    "    \"TC 4 | SF 10\": df_4_10,\n",
    "    \"TC 8 | SF 10\": df_8_10,\n",
    "    \"TC 1 | SF 50\": df_1_50,\n",
    "    \"TC 4 | SF 50\": df_4_50,\n",
    "    \"TC 8 | SF 50\": df_8_50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_boxplots(dfs_dict, column, title, y):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))  \n",
    "        \n",
    "    for (df_name, df), ax in zip(dfs_dict.items(), axes.flatten()):\n",
    "        data_to_plot = [df[df['query'] == query][column] for query in df['query'].unique()]\n",
    "        query_labels = [f\"Query {query}\" for query in df['query'].unique()]\n",
    "        \n",
    "        ax.boxplot(data_to_plot, tick_labels=query_labels, showmeans = True)\n",
    "        ax.set_title(df_name)  \n",
    "        ax.set_ylabel(y)\n",
    "        ax.grid(True)\n",
    "    \n",
    "    for ax in axes.flatten()[len(dfs_dict):]:\n",
    "        ax.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_boxplots(datasets,'cpu_time','CPU Time','CPU Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_boxplots(datasets,'latency','Latency','Latency Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_boxplots(datasets,'cumulative_rows_scanned','Cumulative Rows Scanned','Rows Scanned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cpu_times['Percentage Difference'] = mean_cpu_times.groupby(\"Scaling Factor\")[\"cpu_time\"].transform(\n",
    "    lambda x: x.pct_change() * 100\n",
    ")\n",
    "\n",
    "mean_cpu_times['Percentage Difference Between Scaling Factors'] = mean_cpu_times.groupby(\"Threads\")[\"cpu_time\"].transform(\n",
    "    lambda x: x.pct_change() * 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_latency['Percentage Difference'] = mean_latency.groupby(\"Scaling Factor\")[\"latency\"].transform(\n",
    "    lambda x: x.pct_change() * 100\n",
    ")\n",
    "\n",
    "mean_latency['Percentage Difference Between Scaling Factors'] = mean_latency.groupby(\"Threads\")[\"latency\"].transform(\n",
    "    lambda x: x.pct_change() * 100\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
